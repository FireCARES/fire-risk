##  fcRun.R
#' Fit models described in the supplied control objects
#'
#' The function takes the control object specifying a series of regression
#' models and runs those models.
#'
#' @param sets Control Object The control object describing the models to run.
#'  This will typically be generated by 'npt'
#' @param n    Integer. Number of bootstrap replications to run in order to
#' estimate the confidence intervals on parameters. n=0 (the default) will not
#' run any bootstrap replicates.
#' @param sink  Character. Specifies the name of the text file to send error
#' messages to. This is ignored! [deprecated]
#'
#' @return NULL
#'
#' @details
#' Creates: an \code{out} object listing output of the models.
#'
#' The reason that \code{out} is created in the global environment rather than
#' returned as an object is that if one of the models errors out, I still
#' get the results of the previous models.
#'
#' This will typically be followed up by a run of \code{\link{fcTest}}
#' @export
#' @examples
#' \dontrun{
#'   fcRun(mr.d.00, sink="messages.13.txt")
#'   fcRun(mr.f.S0b, n=1000, sink="messages.08.txt")
#'   fcRun(mr.j.L0a)
#' }
fcRun <- function(sets, n=0, sink=NULL)
{
# In each model, 'library' specfies the R library that will be needed to run the model.
# Here I extract a list of all those libraries and load them.
	for(i in unique(sapply(sets$models,  function(x) x$fn['library']))) library(i, character.only=TRUE)  # loadNamespace(i)

    out <<- list()
# This sets up my 'error' sink file, if 'sink' is correctly specified.
    openLog()
    ctxt <- getContext()
# Now we iterate through the models.
    for(k in names(sets$models))
    {
# I don't know why I allow for a 'null' library, but I do. Any model with
# a null library is skipped and no analysis is run.
        if(tolower(sets$models[[k]]$fn['library']) == "null") next

# Create the output slot for model output.
        out[[k]] <<- list()
# Here I extract the name of the function to be used.
# In a rare cases, I may specify the function with a '::' (or possibly
# '$') value. That means that the actual function used is not the one that
# R would normally pick. This really only applies to lasso and ranger
# models (and really, only ranger, since there is no 'lasso' function
# in the glmnet package). For normal usage, this is not necessary.
# This will only be needed if a user wanted to call the 'ranger' function
# directly rather than through the interface set up here.
        fn  <- sets$models[[k]]$fn['ff']
        if(length(grep("::|[$]", fn)) > 0){
            env <- strsplit(fn, "::|[$]")[[1]]
            fn  <- env[2]
            env <- env[1]
            specify=TRUE
        } else {
            env <- sets$models[[k]]$fn['library']
            specify=FALSE
        }
# Pull the inputs. Subset is handled differently, so extract it. Pull the
# (name of the) data.
        aa <- a <- sets$models[[k]]$inputs
        subset.a <- a$subset
        a$subset <- NULL
        data <- a$data
# In some versions, different models are run for different subsets of the
# data. the sets$runs section of the control object determines this. Here
# we iterate through each subset of the data which will have its own model.
#
# Note that in a previous version of this function, I allowed runs to be
# nested. I have deleted the functionality that handled the nested runs.
# That means there are some control objects out there that will not work
# with this version of the run function. However, any control object produced
# by the current version of npt should work.
        for(i in names(sets$runs))
        {
            setContext(c(ctxt,
                         paste0("Model: ", format(k, width=16)),
                         paste0(  "Run: ", format(i, width=16))))
            msgOut(type="start")
# Create the space where the model results will go, and build the subset name
# for this specific (sub-)model.
            out[[k]][[i]] <<- list()
            aa$subset <- substitute(u & v & set %in% c("training", "validation"), list(u=sets$runs[[i]], v=subset.a))
# Run the (sub-)model
# Since this is set up to run multiple models in batches, catch any errors
# and route them to the error file with enough information to identify which
# model the error was for.
# This will skip any models that error out, and will continue processing the
# remaining models.
            tryCatch(
                {
                    if(specify || ! exists(fn)){
                        out[[k]][[i]]$model <<- do.call(fn, aa, envir=getNamespace(env), quote=TRUE)
                    } else {
                        out[[k]][[i]]$model <<- do.call(fn, aa)
                    }
                },
                error  =function(e) msgOut(e$message, type="error"),
                message=function(e) msgOut(e$message, type="message"))
# If I have asked for bootstrapping of the results, then run the bootstrap.
# This starts by subsetting the data according to the subset defined above,
# then it runs the bootstrap.
            if(n > 0)
            {
                dta <- do.call("subset", list(x=data, subset=aa$subset))
                if(interactive()) pb <- winProgressBar(title=paste("Bootstrapping ", k, " model: ", i, " ", j, ": ", n, " iterations", sep=""), label="0", max=n)
                    out[[k]][[i]]$boot <<- boot(dta, bbb, R=n, strata=dta$fd_id, a=a, fn=fn, pb=pb, nme=names(fixef(out[[k]][[i]]$model)))
                if(interactive()) close(pb)
            }

            msgOut("Elapsed time: ", type="stop")
        }
    }
}




#' LASSO helper function
#'
#' This is a helper function that \code{\link{fcRun}} calls whenever a LASSO model is used.
#'
#' @param formula Formula. This describes the model that the LASSO fits.
#' @param data Data Frame. The data used for the model.
#' @param subset Name. This defines the subset of the data the model is
#' evaluated over.
#' @param ... Additional parameters to the \code{\link[glmnet]{cv.glmnet}} function.
#'
#' @return Returns the glmnet.lasso object with the call slot altered to
#' reflect the call to this function rather than the glmnet function.
#'
#' @details
#' Basically it takes the standard inputs from the \code{\link{fcRun}} routine and translates
#' them to work with the glmnet \code{\link[glmnet]{cv.glmnet}} function.
lasso <- function(formula, data, subset=NULL, ...)
{
#   Get the argument list for the function
    cll <- match.call()
    argg <- as.list(cll)[-1]

#   Unlike all the other models used here, 'glmnet' does not use the formula interface.
#   This section is intended to take formula / data input and adjust it to fit the glmnet
#   interface.
    aaa <- list(formula=argg$formula, data=argg$data)
    if(! is.null(argg$subset))    aaa$subset <- argg$subset
    if("offset" %in% names(argg)) aaa$offset <- argg$offset
    dta <- do.call("model.frame", aaa)

#   create the x, y and offset matrices/vectors that are needed by glmnet.
    argg$x <- model.matrix(argg$formula, dta)
    argg$y <- model.response(dta)
    if("offset" %in% names(argg)) argg$offset <- model.offset(dta)
#   Regardless, remove the 'formula', 'subset' and 'data' arguments from the argument list.
    argg$formula <- NULL
    argg$data    <- NULL
    argg$subset  <- NULL
#   And take care of an annoying issue with the 'family' parameter
    if("family" %in% names(argg) & ! is.character(argg$family)){
        argg$family <- deparse(argg$family)
    }

#   call the main 'cv.glmnet' function with the modified function list and set up a parallel cluster for it.
    if( isNamespaceLoaded( "doParallel" ) ) registerDoParallel()
    if( isNamespaceLoaded( "doParallel" ) ) argg$parallel <- TRUE
    out <- do.call(glmnet::cv.glmnet, argg)
    if( isNamespaceLoaded( "doParallel" ) ) stopImplicitCluster()
    out$call <- cll
    out
}

#' ranger helper function
#'
#' This is a helper function that \code{\link{fcRun}} calls whenever a ranger model is used.
#'
#' @param formula Formula. This describes the model that the Random Forest fits.
#' @param data Data Frame. The data used for the model.
#' @param subset Name. This defines the subset of the data the model is
#' evaluated over.
#' @param ... Additional parameters to the \code{\link[ranger]{ranger}} function.
#'
#' @return Returns the ranger object with the call slot altered to
#' reflect the call to this function rather than the ranger function.
#'
#' @details
#' Basically it takes the standard inputs from the 'run' routine and translates
#' them to work with the \code{\link[ranger]{ranger}} function.
#'
#' There are two reasons why this helper function exists: first, the default ranger
#' function does not have a subset argument. Second, the weights, when they are used,
#' need to be converted from symbol (or quote) to a vector.
ranger <- function(formula, data, subset=NULL, ...)
{
#   Get the argument list for the function
    cll <- match.call()
    argg <- as.list(cll)[-1]
	subset <- substitute(subset)
#   If the "subset" argument is included, subset the data to pass on to the main 'ranger'
#   function.
    if(! is.null(argg$subset)) {
        s <- eval(argg$subset, data)
        argg$data <- do.call("subset", list(x=data, subset=s))
    }
#   Regardless, remove the 'subset' argument from the argument list.
    argg$subset <- NULL
#   If the "case.weights" argument is included, convert it to a vector.
    if("case.weights" %in% names(argg)) {
        argg$case.weights <- eval(argg$case.weights, argg$data)
    }
#   Make sure that the 'write.forest', 'importance' and 'verbose' arguments are included
#   unless they have been specifically excluded. Note that if write.forest has been, we won't
#   be able to generate predictions, and if importance has been, we will lose some information
#   about the model.
    if(! "write.forest" %in% names(argg)) argg$write.forest <- TRUE
    if(! "importance"   %in% names(argg)) argg$importance   <- "impurity"
    if(! "verbose"      %in% names(argg)) argg$verbose      <- FALSE
#
#   call the main 'ranger' function with the modified function list.
#   browser()
    out <- do.call("ranger", argg, envir=getNamespace("ranger"))
    out$call <- cll
    out
}
